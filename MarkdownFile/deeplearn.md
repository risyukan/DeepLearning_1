# 从零开始的深度学习笔记
## 1.multi-layered perceptron
![alt text](1730010147874.png)
看上去是3层构造，但是实际上只有两层有权重，所以是2层感知机。
## 2.sigmoid function
![alt text](78a0a59172e4ea4dd75e711a0d8239a.png)
## 3.sigmoid函数图像
![alt text](1730638215829.png)
線形関数の問題点は、どんなに層を深くしても、それと同じことを行う「隠れ層のないネットワーク」が必ず存在する、という事実に起因します。
## 4.ReLU函数
NumPyのmaximumという関数を使っています。このmaximumは、入力された値から大きいほうの値を選んで出力する関数です。
## 5.神经网络
![alt text](1730726168029.png)
这里需要注意的是，numpy里的1维行列可以看作行，也可以看作列，来进行计算。
![alt text](1730875296950.png)
机器学习中的问题可以大致分类为回归问题和分类问题，回归问题比如说从人物图像中预测这个人的体重等一系列的数值。
**分类问题使用softmax函数**
## 6.softmax函数
![alt text](1730891791059.png)
![alt text](1730891832102.png)
![alt text](1730979309947.png)
ソフトマックスの指数関数の計算を行う際には、何らかの定数を足し算（もしくは、引き算）しても結果は変わらない、ということです。

**对于输入ak（n个数），加上任意常数，不改变结果**

ここでC′にはどのような値を用いることもできますが、オーバーフローの対策としては、入力信号の中で最大の値を用いることが一般的です。

**一般情况下在模型推论时，会省略softmax函数。那为什么要在输出层使用softmax函数呢？ 原因与模型学习时有关。** 

输出层的个数 = 分类问题中类别的个数

## 7.MNISTデータセット
load_mnist 関数は、「(訓練画像, 訓練ラベル), (テスト画像, テストラベル)」という形式で、読み込んだMNISTデータを返します。また、引数として、load_mnist(normalize=True, flatten=True, one_hot_label=False) のように、3つの引数を設定することができます。
**第一个参数可以把画像的像素通道正则化0到1之间**
**第二个参数可以把画像的1x28x28的三维矩阵化为784的一维矩阵**
**第三个参数可以把图像标签转换为one-hot形式，这个形式可以把2转换成【0，0，1，0，0，0，0，0，0，0】**

**<font color=red>加载这个数据集的时候，要把当前工作目录设置在运行脚本这个目录上，然后使用代码把上一级的目录加入到查找路径中，这样才能正确导入dataset这个文件里的mnist.py</font>**